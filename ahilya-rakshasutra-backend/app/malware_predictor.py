# app/malware_predictor.py
from __future__ import annotations
from pathlib import Path
import pickle, warnings
from typing import Dict, Any, List, Optional
import pandas as pd
from androguard.misc import AnalyzeAPK

warnings.filterwarnings("ignore")

BACKEND_ROOT = Path(__file__).resolve().parents[1]
MODELS_DIR = BACKEND_ROOT / "models"
UPLOAD_DIR = BACKEND_ROOT / "uploads"  # change to "upload" if that's your real dir

# Your files (names per your latest message)
MODEL_FILE = MODELS_DIR / "realistic_random_forest_optimized.pkl"
SCALER_FILE = MODELS_DIR / "realistic_scaler.pkl"
FEATURES_FILE = MODELS_DIR / "realistic_feature_names.pkl"

# The 15 permissions we one-hot
REALISTIC_PERMISSIONS = [
    'android.permission.INTERNET',
    'android.permission.READ_PHONE_STATE',
    'android.permission.ACCESS_WIFI_STATE',
    'android.permission.WAKE_LOCK',
    'android.permission.WRITE_EXTERNAL_STORAGE',
    'android.permission.ACCESS_NETWORK_STATE',
    'android.permission.GET_TASKS',
    'android.permission.SYSTEM_ALERT_WINDOW',
    'android.permission.ACCESS_COARSE_LOCATION',
    'android.permission.ACCESS_FINE_LOCATION',
    'android.permission.SEND_SMS',
    'android.permission.CALL_PHONE',
    'android.permission.READ_CONTACTS',
    'android.permission.CAMERA',
    'android.permission.RECORD_AUDIO'
]

# Canonical 19-feature schema: 4 counts + 15 permission flags
FEATURE_ORDER_DEFAULT = (
    ["num_permissions", "num_activities", "num_services", "num_receivers"] +
    [f"perm_{p.replace('android.permission.', '').replace('.', '_')}" for p in REALISTIC_PERMISSIONS]
)

class APKMalwarePredictor:
    def __init__(self):
        self.model = None
        self.scaler = None
        self.feature_names: List[str] = []
        self._load_artifacts()

    def _load_artifacts(self):
        # Load model
        with open(MODEL_FILE, "rb") as f:
            self.model = pickle.load(f)

        # Load scaler if present
        try:
            with open(SCALER_FILE, "rb") as f:
                self.scaler = pickle.load(f)
        except FileNotFoundError:
            self.scaler = None

        # Load feature names; validate length; fallback to default 19
        names = None
        try:
            with open(FEATURES_FILE, "rb") as f:
                names = pickle.load(f)
        except FileNotFoundError:
            names = None

        if isinstance(names, (list, tuple)) and len(names) == len(FEATURE_ORDER_DEFAULT):
            self.feature_names = list(names)
        else:
            # Use our canonical order when missing or wrong-length
            self.feature_names = list(FEATURE_ORDER_DEFAULT)

    def _create_feature_vector(
        self,
        permissions: List[str],
        activities: List[str],
        services: List[str],
        receivers: List[str],
        api_calls: List[str],
    ) -> Dict[str, Any]:
        features: Dict[str, Any] = {}
        features["num_permissions"] = len(permissions)
        features["num_activities"] = len(activities)
        features["num_services"] = len(services)
        features["num_receivers"] = len(receivers)

        perms_set = set(permissions or [])
        for perm in REALISTIC_PERMISSIONS:
            key = f"perm_{perm.replace('android.permission.', '').replace('.', '_')}"
            features[key] = 1 if perm in perms_set else 0

        return features

    def _extract(self, apk_path: Path) -> Optional[Dict[str, Any]]:
        try:
            a, d, dx = AnalyzeAPK(str(apk_path))
            package_name = a.get_package()
            file_size = apk_path.stat().st_size

            permissions = a.get_permissions() or []
            activities = a.get_activities() or []
            services = a.get_services() or []
            receivers = a.get_receivers() or []

            # If you actually use api_calls later, great. Otherwise this is noise.
            api_calls = []
            for method in dx.get_methods():
                try:
                    api_calls.append(f"{method.class_name};->{method.name}")
                except Exception:
                    continue

            features = self._create_feature_vector(
                permissions, activities, services, receivers, api_calls
            )

            return {
                "package_name": package_name,
                "file_size": file_size,
                "permissions": permissions,
                "activities": activities,
                "services": services,
                "receivers": receivers,
                "api_calls": api_calls,
                "features": features,
            }
        except Exception as e:
            return {"error": f"Analyze failed: {e}"}

    def _make_feature_df(self, feature_dict: Dict[str, Any]) -> pd.DataFrame:
        df = pd.DataFrame([feature_dict])

        # Ensure every required column exists; fill missing with 0
        for col in self.feature_names:
            if col not in df.columns:
                df[col] = 0

        # Drop unexpected junk and enforce exact order
        df = df.reindex(columns=self.feature_names, fill_value=0)

        # Optional scaling. Match this to how you trained the scaler.
        if self.scaler is not None:
            # Common case: scaler trained on the 4 count features only
            numeric_cols = [c for c in ["num_permissions", "num_activities", "num_services", "num_receivers"] if c in df.columns]
            if numeric_cols:
                df[numeric_cols] = self.scaler.transform(df[numeric_cols])

            # If you trained the scaler on ALL features, comment the block above and use:
            # df[df.columns] = self.scaler.transform(df[df.columns])

        return df

    def predict_single(self, apk_file_name: str, detailed: bool = False) -> Optional[Dict[str, Any]]:
        apk_path = (UPLOAD_DIR / apk_file_name).resolve()
        if not apk_path.is_file():
            return {"error": f"File not found in upload dir: {apk_file_name}"}

        data = self._extract(apk_path)
        if not data or "error" in data:
            return {"error": data["error"] if data else "Extraction failed"}

        feature_df = self._make_feature_df(data["features"])

        try:
            pred = self.model.predict(feature_df)[0]
            proba = getattr(self.model, "predict_proba", None)
            if callable(proba):
                probs = self.model.predict_proba(feature_df)[0]
                benign_conf = float(probs[0]) if len(probs) > 0 else 0.0
                mal_conf = float(probs[1]) if len(probs) > 1 else 0.0
            else:
                benign_conf, mal_conf = (0.0, 0.0)

            risk = "MALICIOUS" if pred == 1 else "BENIGN"
            risk_level = (
                "HIGH" if mal_conf > 0.8 else
                "MEDIUM" if mal_conf > 0.6 else
                "LOW" if mal_conf > 0.4 else
                "MINIMAL"
            )

            return {
                "apk_file": apk_file_name,
                "package_name": data["package_name"],
                "file_size": data["file_size"],
                "prediction": risk,
                "malicious_confidence": mal_conf,
                "benign_confidence": benign_conf,
                "risk_level": risk_level,
                "details": data if detailed else None
            }
        except Exception as e:
            return {"error": f"Prediction failed: {e}"}

    def predict_all(self, detailed: bool = False) -> List[Dict[str, Any]]:
        if not UPLOAD_DIR.exists():
            return [{"error": f"Upload directory not found: {UPLOAD_DIR}"}]

        apks = sorted([p.name for p in UPLOAD_DIR.iterdir() if p.suffix.lower() == ".apk"])
        results: List[Dict[str, Any]] = []
        for name in apks:
            res = self.predict_single(name, detailed=detailed)
            if res:
                results.append(res)
        return results
